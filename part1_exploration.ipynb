{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Exploration and Preprocessing\n",
    "\n",
    "In this notebook, you will implement functions to load, preprocess, and visualize physiological data from the Wearable Exam Stress Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Set style for plots\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "Implement the `load_data` function to read and organize the physiological data from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(data_dir='~/Documents/4-it-s-about-time-kanting6/data'):\n",
    "    \"\"\"\n",
    "    Load and organize the physiological data from the dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir : str\n",
    "        Path to the directory containing the dataset files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing the organized physiological data with columns:\n",
    "        ['timestamp', 'heart_rate', 'eda', 'temperature', 'subject_id', 'session']\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir).expanduser()\n",
    "    all_records = []\n",
    "\n",
    "    # Search for participant folders (S1, S2, etc.)\n",
    "    for subj_folder in sorted(data_dir.glob('S*')):\n",
    "        subject_id = subj_folder.name\n",
    "\n",
    "        # Search for exam sessions inside each subject folder\n",
    "        for session_folder in sorted(subj_folder.glob('*')):\n",
    "            session = session_folder.name\n",
    "\n",
    "            # Define paths for the required CSV files\n",
    "            hr_file = session_folder / 'HR.csv'\n",
    "            eda_file = session_folder / 'EDA.csv'\n",
    "            temp_file = session_folder / 'TEMP.csv'\n",
    "\n",
    "            # Check that all required files exist\n",
    "            if not (hr_file.exists() and eda_file.exists() and temp_file.exists()):\n",
    "                continue  # Skip if any file is missing\n",
    "\n",
    "            # Load each file\n",
    "            hr_df = pd.read_csv(hr_file, header=None, names=['timestamp', 'heart_rate'])\n",
    "            eda_df = pd.read_csv(eda_file, header=None, names=['timestamp', 'eda'])\n",
    "            temp_df = pd.read_csv(temp_file, header=None, names=['timestamp', 'temperature'])\n",
    "\n",
    "            # Merge on timestamp\n",
    "            merged = hr_df.merge(eda_df, on='timestamp', how='outer')\n",
    "            merged = merged.merge(temp_df, on='timestamp', how='outer')\n",
    "\n",
    "            # Add subject_id and session\n",
    "            merged['subject_id'] = subject_id\n",
    "            merged['session'] = session\n",
    "\n",
    "            # Collect this subject-session dataframe\n",
    "            all_records.append(merged)\n",
    "\n",
    "    # Concatenate all records into one big DataFrame\n",
    "    df = pd.concat(all_records, ignore_index=True)\n",
    "\n",
    "    # Optional: sort by subject, session, timestamp\n",
    "    df = df.sort_values(by=['subject_id', 'session', 'timestamp']).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# df = load_data()\n",
    "# print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "Implement the `preprocess_data` function to clean and prepare the data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, output_dir='~/Documents/4-it-s-about-time-kanting6/data/processed'):\n",
    "    \"\"\"Clean and prepare the physiological data for analysis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Raw physiological data.\n",
    "    output_dir : str\n",
    "        Directory to save processed data files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned and preprocessed data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create output directory\n",
    "    output_dir = Path(output_dir).expanduser()\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1. Handle missing values\n",
    "    missing_ratio = data.isna().mean()\n",
    "    if (missing_ratio > 0.01).any():\n",
    "        raise ValueError(\"More than 1% missing values detected. Please check your data.\")\n",
    "    else:\n",
    "        data = data.fillna(method='ffill').fillna(method='bfill')  # forward fill then backfill\n",
    "\n",
    "    # 2. Resample to regular intervals\n",
    "    # Assume that each (subject_id, session) is a separate time series\n",
    "    processed_list = []\n",
    "    for (subject, session), group in data.groupby(['subject_id', 'session']):\n",
    "        group = group.sort_values('timestamp')\n",
    "\n",
    "        # If timestamp is datetime, set it as index; else assume numeric\n",
    "        if np.issubdtype(group['timestamp'].dtype, np.datetime64):\n",
    "            group = group.set_index('timestamp')\n",
    "\n",
    "            # Resample to 1-minute intervals\n",
    "            group = group.resample('1T').mean()\n",
    "\n",
    "            # Fill missing after resampling\n",
    "            group = group.interpolate(method='time').fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "            group['subject_id'] = subject\n",
    "            group['session'] = session\n",
    "            group = group.reset_index()\n",
    "        else:\n",
    "            pass  # could implement if needed later\n",
    "\n",
    "        processed_list.append(group)\n",
    "\n",
    "    processed_data = pd.concat(processed_list, ignore_index=True)\n",
    "\n",
    "    # 3. Remove outliers using z-score method (threshold=3.5)\n",
    "    physiological_cols = ['heart_rate', 'eda', 'temperature']\n",
    "    z_scores = np.abs(stats.zscore(processed_data[physiological_cols], nan_policy='omit'))\n",
    "\n",
    "    mask = (z_scores < 3.5).all(axis=1)\n",
    "    processed_data = processed_data[mask].reset_index(drop=True)\n",
    "\n",
    "    # 4. Save processed data\n",
    "    for subject_id, subject_df in processed_data.groupby('subject_id'):\n",
    "        filename_base = output_dir / f\"S{subject_id}_processed\"\n",
    "\n",
    "        # Save in all three formats\n",
    "        subject_df.to_csv(f\"{filename_base}.csv\", index=False)\n",
    "        subject_df.to_parquet(f\"{filename_base}.parquet\", index=False)\n",
    "        subject_df.to_feather(f\"{filename_base}.feather\")\n",
    "\n",
    "    return processed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualization\n",
    "\n",
    "Implement the `plot_physiological_signals` function to create visualizations of the physiological data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_physiological_signals(data, subject_id, session, output_dir='~/Documents/4-it-s-about-time-kanting6/plots'):\n",
    "    \"\"\"Create plots of physiological signals for a given subject and session.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Preprocessed physiological data.\n",
    "    subject_id : str\n",
    "        Subject identifier (e.g., 'S1').\n",
    "    session : str\n",
    "        Session identifier (e.g., 'Midterm 1').\n",
    "    output_dir : str\n",
    "        Directory to save plot files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        Figure object containing the plots.\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = Path(output_dir).expanduser()\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1. Filter data for the specific subject and session\n",
    "    subject_num = subject_id.lstrip('S')  \n",
    "    session_data = data[(data['subject_id'].astype(str) == str(subject_num)) & \n",
    "                        (data['session'] == session)]\n",
    "\n",
    "    if session_data.empty:\n",
    "        raise ValueError(f\"No data found for subject {subject_id} and session {session}.\")\n",
    "\n",
    "    # 2. Create figure with subplots\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(15, 10), sharex=True)\n",
    "    fig.suptitle(f'Physiological Signals for {subject_id} - {session}', fontsize=16)\n",
    "\n",
    "    # 3. Plot each physiological signal\n",
    "    signals = ['heart_rate', 'eda', 'temperature']\n",
    "    titles = ['Heart Rate (bpm)', 'Electrodermal Activity (EDA)', 'Temperature (Â°C)']\n",
    "\n",
    "    for ax, signal, title in zip(axs, signals, titles):\n",
    "        ax.plot(session_data['timestamp'], session_data[signal], label=title)\n",
    "        ax.set_ylabel(title)\n",
    "        ax.legend(loc='upper right')\n",
    "        ax.grid(True)\n",
    "\n",
    "    axs[-1].set_xlabel('Time')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96]) \n",
    "\n",
    "    # 4. Save plot to file\n",
    "    clean_session = session.replace(' ', '_').replace('/', '_')\n",
    "    plot_filename = output_dir / f\"{subject_id}_{clean_session}_signals.png\"\n",
    "    fig.savefig(plot_filename)\n",
    "\n",
    "    return fig\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
